{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2c1ada",
   "metadata": {
    "id": "aa2c1ada"
   },
   "source": [
    "# Dreambooth\n",
    "### Notebook implementation by Joe Penna (@MysteryGuitarM on Twitter) - Improvements by David Bielejeski\n",
    "\n",
    "### Instructions\n",
    "- Sign up for RunPod here: https://runpod.io/?ref=n8yfwyum\n",
    "    - Note: That's my personal referral link. Please don't use it if we are mortal enemies.\n",
    "\n",
    "- Click *Deploy* on either `SECURE CLOUD` or `COMMUNITY CLOUD`\n",
    "\n",
    "- Follow the rest of the instructions in this video: https://www.youtube.com/watch?v=7m__xadX0z0#t=5m33.1s\n",
    "\n",
    "Latest information on:\n",
    "https://github.com/JoePenna/Dreambooth-Stable-Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b971cc0",
   "metadata": {
    "id": "7b971cc0"
   },
   "source": [
    "## Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2AsGA1xpNQnb",
   "metadata": {
    "id": "2AsGA1xpNQnb"
   },
   "outputs": [],
   "source": [
    "# If running on Vast.AI, copy the code in this cell into a new notebook. Run it, then launch the `dreambooth_runpod_joepenna.ipynb` notebook from the jupyter interface.\n",
    "!git clone https://github.com/JoePenna/Dreambooth-Stable-Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
   "metadata": {
    "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BUILD ENV\n",
    "!pip install omegaconf\n",
    "!pip install einops\n",
    "!pip install pytorch-lightning==1.6.5\n",
    "!pip install test-tube\n",
    "!pip install transformers\n",
    "!pip install kornia\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install setuptools==59.5.0\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install -e .\n",
    "!pip install protobuf==3.20.1\n",
    "!pip install gdown\n",
    "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip install -qq \"ipywidgets>=7,<8\"\n",
    "!pip install huggingface_hub\n",
    "!pip install ipywidgets==7.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae11c10",
   "metadata": {
    "id": "dae11c10"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f591b48bdb4e488576f7cdade13421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hugging Face Login\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d290b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Download the 1.4 sd model\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"CompVis/stable-diffusion-v-1-4-original\",\n",
    " filename=\"sd-v1-4.ckpt\",\n",
    " use_auth_token=True\n",
    ")\n",
    "\n",
    "# Move the sd-v1-4.ckpt to the root of this directory as \"model.ckpt\"\n",
    "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
    "!mv {actual_locations_of_model_blob[-1]} model.ckpt\n",
    "clear_output()\n",
    "print(\"✅ model.ckpt successfully downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1d11a",
   "metadata": {
    "id": "17d1d11a"
   },
   "source": [
    "# Regularization Images (Skip this section if you are uploading your own or using the provided images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07a5df",
   "metadata": {
    "id": "ed07a5df"
   },
   "source": [
    "Training teaches your new model both your token **but** re-trains your class simultaneously.\n",
    "\n",
    "From cursory testing, it does not seem like reg images affect the model too much. However, they do affect your class greatly, which will in turn affect your generations.\n",
    "\n",
    "You can either generate your images here, or use the repos below to quickly download 1500 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91",
   "metadata": {
    "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91"
   },
   "outputs": [],
   "source": [
    "# GENERATE 200 images - Optional\n",
    "self_generated_files_prompt = \"person\" #@param {type:\"string\"}\n",
    "self_generated_files_count = 200 #@param {type:\"integer\"}\n",
    "\n",
    "!python scripts/stable_txt2img.py \\\n",
    " --seed 10 \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 1 \\\n",
    " --n_iter {self_generated_files_count} \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 50 \\\n",
    " --ckpt model.ckpt \\\n",
    " --prompt {self_generated_files_prompt}\n",
    "\n",
    "dataset=self_generated_files_prompt\n",
    "\n",
    "!mkdir -p regularization_images/{dataset}\n",
    "!mv outputs/txt2img-samples/*.png regularization_images/{dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1c7e1c",
   "metadata": {
    "id": "3d1c7e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "\tzip warning: name not matched: regularization_images/{dataset}\n",
      "\n",
      "zip error: Nothing to do! (try: zip -r regularization_images.zip . -i regularization_images/{dataset})\n"
     ]
    }
   ],
   "source": [
    "# Zip up the files for downloading and reuse.\n",
    "# Download this file locally so you can reuse during another training on this dataset\n",
    "!apt-get install -y zip\n",
    "!zip -r regularization_images.zip regularization_images/{dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9877b",
   "metadata": {},
   "source": [
    "# Download pre-generated regularization images\n",
    "We've created the following image sets\n",
    "\n",
    "`man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
    "`man_unsplash` - pictures from various photographers\n",
    "`person_ddim`\n",
    "`woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0\n",
    "`person_ddim` is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7EydXCjOV1v",
   "metadata": {
    "id": "e7EydXCjOV1v"
   },
   "outputs": [],
   "source": [
    "#Download Regularization Images\n",
    "\n",
    "dataset=\"person_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"blonde_woman\"]\n",
    "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
    "\n",
    "!mkdir -p regularization_images/{dataset}\n",
    "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* regularization_images/{dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88269ef9",
   "metadata": {},
   "source": [
    "# Upload your training images\n",
    "Upload 10-20 images of someone to\n",
    "\n",
    "```\n",
    "/workspace/Dreambooth-Stable-Diffusion/training_images\n",
    "```\n",
    "\n",
    "WARNING: Be sure to upload an *even* amount of images, otherwise the training inexplicably stops at 1500 steps.\n",
    "\n",
    "*   2-3 full body\n",
    "*   3-5 upper body\n",
    "*   5-12 close-up on face\n",
    "\n",
    "The images should be:\n",
    "\n",
    "- as close as possible to the kind of images you're trying to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d424b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#@markdown Add here the URLs to the images of the subject you are adding\n",
    "urls = [\n",
    " \"https://i.imgur.com/test1.png\",\n",
    " \"https://i.imgur.com/test2.png\",\n",
    " \"https://i.imgur.com/test3.png\",\n",
    " \"https://i.imgur.com/test4.png\",\n",
    " \"https://i.imgur.com/test5.png\",\n",
    " # You can add additional images here -- about 20-30 images in different\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e5e6c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#@title Download and check the images you have just added\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    " assert len(imgs) == rows*cols\n",
    "\n",
    " w, h = imgs[0].size\n",
    " grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    " grid_w, grid_h = grid.size\n",
    "\n",
    " for i, img in enumerate(imgs):\n",
    "  grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    " return grid\n",
    "\n",
    "def download_image(url):\n",
    " try:\n",
    "  response = requests.get(url)\n",
    " except:\n",
    "  return None\n",
    " return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "images = list(filter(None,[download_image(url) for url in urls]))\n",
    "save_path = \"./training_images\"\n",
    "if not os.path.exists(save_path):\n",
    " os.mkdir(save_path)\n",
    "[image.save(f\"{save_path}/{i}.png\", format=\"png\") for i, image in enumerate(images)]\n",
    "image_grid(images, 1, len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e50df",
   "metadata": {
    "id": "ad4e50df"
   },
   "source": [
    "## Training\n",
    "\n",
    "If training a person or subject, keep an eye on your project's `logs/{folder}/images/train/samples_scaled_gs-00xxxx` generations.\n",
    "\n",
    "If training a style, keep an eye on your project's `logs/{folder}/images/train/samples_gs-00xxxx` generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
   "metadata": {
    "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "Global seed set to 23\n",
      "Running on GPUs 0,\n",
      "Loading model from /data/chengping/ldm-ckpt/ori/sd-v1-4-full-ema.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'logit_scale', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'text_projection.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'visual_projection.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.13.layer_norm1.weight']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Restored from /data/chengping/ldm-ckpt/ori/sd-v1-4-full-ema.ckpt with 0 missing and 688 unexpected keys\n",
      "Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'model_ema.diffusion_modeltime_embed0weight', 'model_ema.diffusion_modeltime_embed0bias', 'model_ema.diffusion_modeltime_embed2weight', 'model_ema.diffusion_modeltime_embed2bias', 'model_ema.diffusion_modelinput_blocks00weight', 'model_ema.diffusion_modelinput_blocks00bias', 'model_ema.diffusion_modelinput_blocks10in_layers0weight', 'model_ema.diffusion_modelinput_blocks10in_layers0bias', 'model_ema.diffusion_modelinput_blocks10in_layers2weight', 'model_ema.diffusion_modelinput_blocks10in_layers2bias', 'model_ema.diffusion_modelinput_blocks10emb_layers1weight', 'model_ema.diffusion_modelinput_blocks10emb_layers1bias', 'model_ema.diffusion_modelinput_blocks10out_layers0weight', 'model_ema.diffusion_modelinput_blocks10out_layers0bias', 'model_ema.diffusion_modelinput_blocks10out_layers3weight', 'model_ema.diffusion_modelinput_blocks10out_layers3bias', 'model_ema.diffusion_modelinput_blocks11normweight', 'model_ema.diffusion_modelinput_blocks11normbias', 'model_ema.diffusion_modelinput_blocks11proj_inweight', 'model_ema.diffusion_modelinput_blocks11proj_inbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks11transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks11proj_outweight', 'model_ema.diffusion_modelinput_blocks11proj_outbias', 'model_ema.diffusion_modelinput_blocks20in_layers0weight', 'model_ema.diffusion_modelinput_blocks20in_layers0bias', 'model_ema.diffusion_modelinput_blocks20in_layers2weight', 'model_ema.diffusion_modelinput_blocks20in_layers2bias', 'model_ema.diffusion_modelinput_blocks20emb_layers1weight', 'model_ema.diffusion_modelinput_blocks20emb_layers1bias', 'model_ema.diffusion_modelinput_blocks20out_layers0weight', 'model_ema.diffusion_modelinput_blocks20out_layers0bias', 'model_ema.diffusion_modelinput_blocks20out_layers3weight', 'model_ema.diffusion_modelinput_blocks20out_layers3bias', 'model_ema.diffusion_modelinput_blocks21normweight', 'model_ema.diffusion_modelinput_blocks21normbias', 'model_ema.diffusion_modelinput_blocks21proj_inweight', 'model_ema.diffusion_modelinput_blocks21proj_inbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks21transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks21proj_outweight', 'model_ema.diffusion_modelinput_blocks21proj_outbias', 'model_ema.diffusion_modelinput_blocks30opweight', 'model_ema.diffusion_modelinput_blocks30opbias', 'model_ema.diffusion_modelinput_blocks40in_layers0weight', 'model_ema.diffusion_modelinput_blocks40in_layers0bias', 'model_ema.diffusion_modelinput_blocks40in_layers2weight', 'model_ema.diffusion_modelinput_blocks40in_layers2bias', 'model_ema.diffusion_modelinput_blocks40emb_layers1weight', 'model_ema.diffusion_modelinput_blocks40emb_layers1bias', 'model_ema.diffusion_modelinput_blocks40out_layers0weight', 'model_ema.diffusion_modelinput_blocks40out_layers0bias', 'model_ema.diffusion_modelinput_blocks40out_layers3weight', 'model_ema.diffusion_modelinput_blocks40out_layers3bias', 'model_ema.diffusion_modelinput_blocks40skip_connectionweight', 'model_ema.diffusion_modelinput_blocks40skip_connectionbias', 'model_ema.diffusion_modelinput_blocks41normweight', 'model_ema.diffusion_modelinput_blocks41normbias', 'model_ema.diffusion_modelinput_blocks41proj_inweight', 'model_ema.diffusion_modelinput_blocks41proj_inbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks41proj_outweight', 'model_ema.diffusion_modelinput_blocks41proj_outbias', 'model_ema.diffusion_modelinput_blocks50in_layers0weight', 'model_ema.diffusion_modelinput_blocks50in_layers0bias', 'model_ema.diffusion_modelinput_blocks50in_layers2weight', 'model_ema.diffusion_modelinput_blocks50in_layers2bias', 'model_ema.diffusion_modelinput_blocks50emb_layers1weight', 'model_ema.diffusion_modelinput_blocks50emb_layers1bias', 'model_ema.diffusion_modelinput_blocks50out_layers0weight', 'model_ema.diffusion_modelinput_blocks50out_layers0bias', 'model_ema.diffusion_modelinput_blocks50out_layers3weight', 'model_ema.diffusion_modelinput_blocks50out_layers3bias', 'model_ema.diffusion_modelinput_blocks51normweight', 'model_ema.diffusion_modelinput_blocks51normbias', 'model_ema.diffusion_modelinput_blocks51proj_inweight', 'model_ema.diffusion_modelinput_blocks51proj_inbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks51proj_outweight', 'model_ema.diffusion_modelinput_blocks51proj_outbias', 'model_ema.diffusion_modelinput_blocks60opweight', 'model_ema.diffusion_modelinput_blocks60opbias', 'model_ema.diffusion_modelinput_blocks70in_layers0weight', 'model_ema.diffusion_modelinput_blocks70in_layers0bias', 'model_ema.diffusion_modelinput_blocks70in_layers2weight', 'model_ema.diffusion_modelinput_blocks70in_layers2bias', 'model_ema.diffusion_modelinput_blocks70emb_layers1weight', 'model_ema.diffusion_modelinput_blocks70emb_layers1bias', 'model_ema.diffusion_modelinput_blocks70out_layers0weight', 'model_ema.diffusion_modelinput_blocks70out_layers0bias', 'model_ema.diffusion_modelinput_blocks70out_layers3weight', 'model_ema.diffusion_modelinput_blocks70out_layers3bias', 'model_ema.diffusion_modelinput_blocks70skip_connectionweight', 'model_ema.diffusion_modelinput_blocks70skip_connectionbias', 'model_ema.diffusion_modelinput_blocks71normweight', 'model_ema.diffusion_modelinput_blocks71normbias', 'model_ema.diffusion_modelinput_blocks71proj_inweight', 'model_ema.diffusion_modelinput_blocks71proj_inbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks71proj_outweight', 'model_ema.diffusion_modelinput_blocks71proj_outbias', 'model_ema.diffusion_modelinput_blocks80in_layers0weight', 'model_ema.diffusion_modelinput_blocks80in_layers0bias', 'model_ema.diffusion_modelinput_blocks80in_layers2weight', 'model_ema.diffusion_modelinput_blocks80in_layers2bias', 'model_ema.diffusion_modelinput_blocks80emb_layers1weight', 'model_ema.diffusion_modelinput_blocks80emb_layers1bias', 'model_ema.diffusion_modelinput_blocks80out_layers0weight', 'model_ema.diffusion_modelinput_blocks80out_layers0bias', 'model_ema.diffusion_modelinput_blocks80out_layers3weight', 'model_ema.diffusion_modelinput_blocks80out_layers3bias', 'model_ema.diffusion_modelinput_blocks81normweight', 'model_ema.diffusion_modelinput_blocks81normbias', 'model_ema.diffusion_modelinput_blocks81proj_inweight', 'model_ema.diffusion_modelinput_blocks81proj_inbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modelinput_blocks81proj_outweight', 'model_ema.diffusion_modelinput_blocks81proj_outbias', 'model_ema.diffusion_modelinput_blocks90opweight', 'model_ema.diffusion_modelinput_blocks90opbias', 'model_ema.diffusion_modelinput_blocks100in_layers0weight', 'model_ema.diffusion_modelinput_blocks100in_layers0bias', 'model_ema.diffusion_modelinput_blocks100in_layers2weight', 'model_ema.diffusion_modelinput_blocks100in_layers2bias', 'model_ema.diffusion_modelinput_blocks100emb_layers1weight', 'model_ema.diffusion_modelinput_blocks100emb_layers1bias', 'model_ema.diffusion_modelinput_blocks100out_layers0weight', 'model_ema.diffusion_modelinput_blocks100out_layers0bias', 'model_ema.diffusion_modelinput_blocks100out_layers3weight', 'model_ema.diffusion_modelinput_blocks100out_layers3bias', 'model_ema.diffusion_modelinput_blocks110in_layers0weight', 'model_ema.diffusion_modelinput_blocks110in_layers0bias', 'model_ema.diffusion_modelinput_blocks110in_layers2weight', 'model_ema.diffusion_modelinput_blocks110in_layers2bias', 'model_ema.diffusion_modelinput_blocks110emb_layers1weight', 'model_ema.diffusion_modelinput_blocks110emb_layers1bias', 'model_ema.diffusion_modelinput_blocks110out_layers0weight', 'model_ema.diffusion_modelinput_blocks110out_layers0bias', 'model_ema.diffusion_modelinput_blocks110out_layers3weight', 'model_ema.diffusion_modelinput_blocks110out_layers3bias', 'model_ema.diffusion_modelmiddle_block0in_layers0weight', 'model_ema.diffusion_modelmiddle_block0in_layers0bias', 'model_ema.diffusion_modelmiddle_block0in_layers2weight', 'model_ema.diffusion_modelmiddle_block0in_layers2bias', 'model_ema.diffusion_modelmiddle_block0emb_layers1weight', 'model_ema.diffusion_modelmiddle_block0emb_layers1bias', 'model_ema.diffusion_modelmiddle_block0out_layers0weight', 'model_ema.diffusion_modelmiddle_block0out_layers0bias', 'model_ema.diffusion_modelmiddle_block0out_layers3weight', 'model_ema.diffusion_modelmiddle_block0out_layers3bias', 'model_ema.diffusion_modelmiddle_block1normweight', 'model_ema.diffusion_modelmiddle_block1normbias', 'model_ema.diffusion_modelmiddle_block1proj_inweight', 'model_ema.diffusion_modelmiddle_block1proj_inbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2bias', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3weight', 'model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3bias', 'model_ema.diffusion_modelmiddle_block1proj_outweight', 'model_ema.diffusion_modelmiddle_block1proj_outbias', 'model_ema.diffusion_modelmiddle_block2in_layers0weight', 'model_ema.diffusion_modelmiddle_block2in_layers0bias', 'model_ema.diffusion_modelmiddle_block2in_layers2weight', 'model_ema.diffusion_modelmiddle_block2in_layers2bias', 'model_ema.diffusion_modelmiddle_block2emb_layers1weight', 'model_ema.diffusion_modelmiddle_block2emb_layers1bias', 'model_ema.diffusion_modelmiddle_block2out_layers0weight', 'model_ema.diffusion_modelmiddle_block2out_layers0bias', 'model_ema.diffusion_modelmiddle_block2out_layers3weight', 'model_ema.diffusion_modelmiddle_block2out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00in_layers0weight', 'model_ema.diffusion_modeloutput_blocks00in_layers0bias', 'model_ema.diffusion_modeloutput_blocks00in_layers2weight', 'model_ema.diffusion_modeloutput_blocks00in_layers2bias', 'model_ema.diffusion_modeloutput_blocks00emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks00emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks00out_layers0weight', 'model_ema.diffusion_modeloutput_blocks00out_layers0bias', 'model_ema.diffusion_modeloutput_blocks00out_layers3weight', 'model_ema.diffusion_modeloutput_blocks00out_layers3bias', 'model_ema.diffusion_modeloutput_blocks00skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks00skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks10in_layers0weight', 'model_ema.diffusion_modeloutput_blocks10in_layers0bias', 'model_ema.diffusion_modeloutput_blocks10in_layers2weight', 'model_ema.diffusion_modeloutput_blocks10in_layers2bias', 'model_ema.diffusion_modeloutput_blocks10emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks10emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks10out_layers0weight', 'model_ema.diffusion_modeloutput_blocks10out_layers0bias', 'model_ema.diffusion_modeloutput_blocks10out_layers3weight', 'model_ema.diffusion_modeloutput_blocks10out_layers3bias', 'model_ema.diffusion_modeloutput_blocks10skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks10skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks20in_layers0weight', 'model_ema.diffusion_modeloutput_blocks20in_layers0bias', 'model_ema.diffusion_modeloutput_blocks20in_layers2weight', 'model_ema.diffusion_modeloutput_blocks20in_layers2bias', 'model_ema.diffusion_modeloutput_blocks20emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks20emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks20out_layers0weight', 'model_ema.diffusion_modeloutput_blocks20out_layers0bias', 'model_ema.diffusion_modeloutput_blocks20out_layers3weight', 'model_ema.diffusion_modeloutput_blocks20out_layers3bias', 'model_ema.diffusion_modeloutput_blocks20skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks20skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks21convweight', 'model_ema.diffusion_modeloutput_blocks21convbias', 'model_ema.diffusion_modeloutput_blocks30in_layers0weight', 'model_ema.diffusion_modeloutput_blocks30in_layers0bias', 'model_ema.diffusion_modeloutput_blocks30in_layers2weight', 'model_ema.diffusion_modeloutput_blocks30in_layers2bias', 'model_ema.diffusion_modeloutput_blocks30emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks30emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks30out_layers0weight', 'model_ema.diffusion_modeloutput_blocks30out_layers0bias', 'model_ema.diffusion_modeloutput_blocks30out_layers3weight', 'model_ema.diffusion_modeloutput_blocks30out_layers3bias', 'model_ema.diffusion_modeloutput_blocks30skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks30skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks31normweight', 'model_ema.diffusion_modeloutput_blocks31normbias', 'model_ema.diffusion_modeloutput_blocks31proj_inweight', 'model_ema.diffusion_modeloutput_blocks31proj_inbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks31proj_outweight', 'model_ema.diffusion_modeloutput_blocks31proj_outbias', 'model_ema.diffusion_modeloutput_blocks40in_layers0weight', 'model_ema.diffusion_modeloutput_blocks40in_layers0bias', 'model_ema.diffusion_modeloutput_blocks40in_layers2weight', 'model_ema.diffusion_modeloutput_blocks40in_layers2bias', 'model_ema.diffusion_modeloutput_blocks40emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks40emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks40out_layers0weight', 'model_ema.diffusion_modeloutput_blocks40out_layers0bias', 'model_ema.diffusion_modeloutput_blocks40out_layers3weight', 'model_ema.diffusion_modeloutput_blocks40out_layers3bias', 'model_ema.diffusion_modeloutput_blocks40skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks40skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks41normweight', 'model_ema.diffusion_modeloutput_blocks41normbias', 'model_ema.diffusion_modeloutput_blocks41proj_inweight', 'model_ema.diffusion_modeloutput_blocks41proj_inbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks41proj_outweight', 'model_ema.diffusion_modeloutput_blocks41proj_outbias', 'model_ema.diffusion_modeloutput_blocks50in_layers0weight', 'model_ema.diffusion_modeloutput_blocks50in_layers0bias', 'model_ema.diffusion_modeloutput_blocks50in_layers2weight', 'model_ema.diffusion_modeloutput_blocks50in_layers2bias', 'model_ema.diffusion_modeloutput_blocks50emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks50emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks50out_layers0weight', 'model_ema.diffusion_modeloutput_blocks50out_layers0bias', 'model_ema.diffusion_modeloutput_blocks50out_layers3weight', 'model_ema.diffusion_modeloutput_blocks50out_layers3bias', 'model_ema.diffusion_modeloutput_blocks50skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks50skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks51normweight', 'model_ema.diffusion_modeloutput_blocks51normbias', 'model_ema.diffusion_modeloutput_blocks51proj_inweight', 'model_ema.diffusion_modeloutput_blocks51proj_inbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks51proj_outweight', 'model_ema.diffusion_modeloutput_blocks51proj_outbias', 'model_ema.diffusion_modeloutput_blocks52convweight', 'model_ema.diffusion_modeloutput_blocks52convbias', 'model_ema.diffusion_modeloutput_blocks60in_layers0weight', 'model_ema.diffusion_modeloutput_blocks60in_layers0bias', 'model_ema.diffusion_modeloutput_blocks60in_layers2weight', 'model_ema.diffusion_modeloutput_blocks60in_layers2bias', 'model_ema.diffusion_modeloutput_blocks60emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks60emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks60out_layers0weight', 'model_ema.diffusion_modeloutput_blocks60out_layers0bias', 'model_ema.diffusion_modeloutput_blocks60out_layers3weight', 'model_ema.diffusion_modeloutput_blocks60out_layers3bias', 'model_ema.diffusion_modeloutput_blocks60skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks60skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks61normweight', 'model_ema.diffusion_modeloutput_blocks61normbias', 'model_ema.diffusion_modeloutput_blocks61proj_inweight', 'model_ema.diffusion_modeloutput_blocks61proj_inbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks61proj_outweight', 'model_ema.diffusion_modeloutput_blocks61proj_outbias', 'model_ema.diffusion_modeloutput_blocks70in_layers0weight', 'model_ema.diffusion_modeloutput_blocks70in_layers0bias', 'model_ema.diffusion_modeloutput_blocks70in_layers2weight', 'model_ema.diffusion_modeloutput_blocks70in_layers2bias', 'model_ema.diffusion_modeloutput_blocks70emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks70emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks70out_layers0weight', 'model_ema.diffusion_modeloutput_blocks70out_layers0bias', 'model_ema.diffusion_modeloutput_blocks70out_layers3weight', 'model_ema.diffusion_modeloutput_blocks70out_layers3bias', 'model_ema.diffusion_modeloutput_blocks70skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks70skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks71normweight', 'model_ema.diffusion_modeloutput_blocks71normbias', 'model_ema.diffusion_modeloutput_blocks71proj_inweight', 'model_ema.diffusion_modeloutput_blocks71proj_inbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks71proj_outweight', 'model_ema.diffusion_modeloutput_blocks71proj_outbias', 'model_ema.diffusion_modeloutput_blocks80in_layers0weight', 'model_ema.diffusion_modeloutput_blocks80in_layers0bias', 'model_ema.diffusion_modeloutput_blocks80in_layers2weight', 'model_ema.diffusion_modeloutput_blocks80in_layers2bias', 'model_ema.diffusion_modeloutput_blocks80emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks80emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks80out_layers0weight', 'model_ema.diffusion_modeloutput_blocks80out_layers0bias', 'model_ema.diffusion_modeloutput_blocks80out_layers3weight', 'model_ema.diffusion_modeloutput_blocks80out_layers3bias', 'model_ema.diffusion_modeloutput_blocks80skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks80skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks81normweight', 'model_ema.diffusion_modeloutput_blocks81normbias', 'model_ema.diffusion_modeloutput_blocks81proj_inweight', 'model_ema.diffusion_modeloutput_blocks81proj_inbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks81proj_outweight', 'model_ema.diffusion_modeloutput_blocks81proj_outbias', 'model_ema.diffusion_modeloutput_blocks82convweight', 'model_ema.diffusion_modeloutput_blocks82convbias', 'model_ema.diffusion_modeloutput_blocks90in_layers0weight', 'model_ema.diffusion_modeloutput_blocks90in_layers0bias', 'model_ema.diffusion_modeloutput_blocks90in_layers2weight', 'model_ema.diffusion_modeloutput_blocks90in_layers2bias', 'model_ema.diffusion_modeloutput_blocks90emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks90emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks90out_layers0weight', 'model_ema.diffusion_modeloutput_blocks90out_layers0bias', 'model_ema.diffusion_modeloutput_blocks90out_layers3weight', 'model_ema.diffusion_modeloutput_blocks90out_layers3bias', 'model_ema.diffusion_modeloutput_blocks90skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks90skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks91normweight', 'model_ema.diffusion_modeloutput_blocks91normbias', 'model_ema.diffusion_modeloutput_blocks91proj_inweight', 'model_ema.diffusion_modeloutput_blocks91proj_inbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks91transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks91proj_outweight', 'model_ema.diffusion_modeloutput_blocks91proj_outbias', 'model_ema.diffusion_modeloutput_blocks100in_layers0weight', 'model_ema.diffusion_modeloutput_blocks100in_layers0bias', 'model_ema.diffusion_modeloutput_blocks100in_layers2weight', 'model_ema.diffusion_modeloutput_blocks100in_layers2bias', 'model_ema.diffusion_modeloutput_blocks100emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks100emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks100out_layers0weight', 'model_ema.diffusion_modeloutput_blocks100out_layers0bias', 'model_ema.diffusion_modeloutput_blocks100out_layers3weight', 'model_ema.diffusion_modeloutput_blocks100out_layers3bias', 'model_ema.diffusion_modeloutput_blocks100skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks100skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks101normweight', 'model_ema.diffusion_modeloutput_blocks101normbias', 'model_ema.diffusion_modeloutput_blocks101proj_inweight', 'model_ema.diffusion_modeloutput_blocks101proj_inbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks101transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks101proj_outweight', 'model_ema.diffusion_modeloutput_blocks101proj_outbias', 'model_ema.diffusion_modeloutput_blocks110in_layers0weight', 'model_ema.diffusion_modeloutput_blocks110in_layers0bias', 'model_ema.diffusion_modeloutput_blocks110in_layers2weight', 'model_ema.diffusion_modeloutput_blocks110in_layers2bias', 'model_ema.diffusion_modeloutput_blocks110emb_layers1weight', 'model_ema.diffusion_modeloutput_blocks110emb_layers1bias', 'model_ema.diffusion_modeloutput_blocks110out_layers0weight', 'model_ema.diffusion_modeloutput_blocks110out_layers0bias', 'model_ema.diffusion_modeloutput_blocks110out_layers3weight', 'model_ema.diffusion_modeloutput_blocks110out_layers3bias', 'model_ema.diffusion_modeloutput_blocks110skip_connectionweight', 'model_ema.diffusion_modeloutput_blocks110skip_connectionbias', 'model_ema.diffusion_modeloutput_blocks111normweight', 'model_ema.diffusion_modeloutput_blocks111normbias', 'model_ema.diffusion_modeloutput_blocks111proj_inweight', 'model_ema.diffusion_modeloutput_blocks111proj_inbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn1to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet0projbias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0ffnet2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_qweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_kweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_vweight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0attn2to_out0bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm1bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm2bias', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3weight', 'model_ema.diffusion_modeloutput_blocks111transformer_blocks0norm3bias', 'model_ema.diffusion_modeloutput_blocks111proj_outweight', 'model_ema.diffusion_modeloutput_blocks111proj_outbias', 'model_ema.diffusion_modelout0weight', 'model_ema.diffusion_modelout0bias', 'model_ema.diffusion_modelout2weight', 'model_ema.diffusion_modelout2bias']\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loggers/test_tube.py:105: LightningDeprecationWarning: The TestTubeLogger is deprecated since v1.5 and will be removed in v1.7. We recommend switching to the `pytorch_lightning.loggers.TensorBoardLogger` as an alternative.\n",
      "  rank_zero_deprecation(\n",
      "Monitoring val/loss_simple_ema as checkpoint metric.\n",
      "Merged modelckpt-cfg: \n",
      "{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/training_images22022-10-07T03-59-51_project_name/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/loss_simple_ema', 'save_top_k': 1, 'every_n_train_steps': 500}}\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "#### Data #####\n",
      "train, PersonalizedBase, 2200\n",
      "reg, PersonalizedBase, 15000\n",
      "validation, PersonalizedBase, 22\n",
      "accumulate_grad_batches = 1\n",
      "++++ NOT USING LR SCALING ++++\n",
      "Setting learning rate to 1.00e-06\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:326: LightningDeprecationWarning: Base `LightningModule.on_train_batch_start` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "  rank_zero_deprecation(\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "  rank_zero_deprecation(\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:342: LightningDeprecationWarning: Base `Callback.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "LatentDiffusion: Also optimizing conditioner params!\n",
      "\n",
      "  | Name              | Type               | Params\n",
      "---------------------------------------------------------\n",
      "0 | model             | DiffusionWrapper   | 859 M \n",
      "1 | first_stage_model | AutoencoderKL      | 83.7 M\n",
      "2 | cond_stage_model  | FrozenCLIPEmbedder | 123 M \n",
      "---------------------------------------------------------\n",
      "982 M     Trainable params\n",
      "83.7 M    Non-trainable params\n",
      "1.1 B     Total params\n",
      "4,264.941 Total estimated model params size (MB)\n",
      "Project config\n",
      "model:\n",
      "  base_learning_rate: 1.0e-06\n",
      "  target: ldm.models.diffusion.ddpm.LatentDiffusion\n",
      "  params:\n",
      "    reg_weight: 1.0\n",
      "    linear_start: 0.00085\n",
      "    linear_end: 0.012\n",
      "    num_timesteps_cond: 1\n",
      "    log_every_t: 200\n",
      "    timesteps: 1000\n",
      "    first_stage_key: image\n",
      "    cond_stage_key: caption\n",
      "    image_size: 64\n",
      "    channels: 4\n",
      "    cond_stage_trainable: true\n",
      "    conditioning_key: crossattn\n",
      "    monitor: val/loss_simple_ema\n",
      "    scale_factor: 0.18215\n",
      "    use_ema: false\n",
      "    embedding_reg_weight: 0.0\n",
      "    unfreeze_model: true\n",
      "    model_lr: 1.0e-06\n",
      "    personalization_config:\n",
      "      target: ldm.modules.embedding_manager.EmbeddingManager\n",
      "      params:\n",
      "        placeholder_strings:\n",
      "        - '*'\n",
      "        initializer_words:\n",
      "        - sculpture\n",
      "        per_image_tokens: false\n",
      "        num_vectors_per_token: 1\n",
      "        progressive_words: false\n",
      "    unet_config:\n",
      "      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n",
      "      params:\n",
      "        image_size: 32\n",
      "        in_channels: 4\n",
      "        out_channels: 4\n",
      "        model_channels: 320\n",
      "        attention_resolutions:\n",
      "        - 4\n",
      "        - 2\n",
      "        - 1\n",
      "        num_res_blocks: 2\n",
      "        channel_mult:\n",
      "        - 1\n",
      "        - 2\n",
      "        - 4\n",
      "        - 4\n",
      "        num_heads: 8\n",
      "        use_spatial_transformer: true\n",
      "        transformer_depth: 1\n",
      "        context_dim: 768\n",
      "        use_checkpoint: true\n",
      "        legacy: false\n",
      "    first_stage_config:\n",
      "      target: ldm.models.autoencoder.AutoencoderKL\n",
      "      params:\n",
      "        embed_dim: 4\n",
      "        monitor: val/rec_loss\n",
      "        ddconfig:\n",
      "          double_z: true\n",
      "          z_channels: 4\n",
      "          resolution: 512\n",
      "          in_channels: 3\n",
      "          out_ch: 3\n",
      "          ch: 128\n",
      "          ch_mult:\n",
      "          - 1\n",
      "          - 2\n",
      "          - 4\n",
      "          - 4\n",
      "          num_res_blocks: 2\n",
      "          attn_resolutions: []\n",
      "          dropout: 0.0\n",
      "        lossconfig:\n",
      "          target: torch.nn.Identity\n",
      "    cond_stage_config:\n",
      "      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder\n",
      "    ckpt_path: /data/chengping/ldm-ckpt/ori/sd-v1-4-full-ema.ckpt\n",
      "data:\n",
      "  target: main.DataModuleFromConfig\n",
      "  params:\n",
      "    batch_size: 1\n",
      "    num_workers: 1\n",
      "    wrap: false\n",
      "    train:\n",
      "      target: ldm.data.personalized.PersonalizedBase\n",
      "      params:\n",
      "        size: 512\n",
      "        set: train\n",
      "        per_image_tokens: false\n",
      "        repeats: 100\n",
      "        coarse_class_text: person\n",
      "        placeholder_token: joyce\n",
      "        token_only: false\n",
      "    reg:\n",
      "      target: ldm.data.personalized.PersonalizedBase\n",
      "      params:\n",
      "        size: 512\n",
      "        set: train\n",
      "        reg: true\n",
      "        per_image_tokens: false\n",
      "        repeats: 10\n",
      "        coarse_class_text: person\n",
      "        placeholder_token: joyce\n",
      "    validation:\n",
      "      target: ldm.data.personalized.PersonalizedBase\n",
      "      params:\n",
      "        size: 512\n",
      "        set: val\n",
      "        per_image_tokens: false\n",
      "        repeats: 10\n",
      "        coarse_class_text: person\n",
      "        placeholder_token: joyce\n",
      "\n",
      "Lightning config\n",
      "modelcheckpoint:\n",
      "  params:\n",
      "    every_n_train_steps: 500\n",
      "callbacks:\n",
      "  image_logger:\n",
      "    target: main.ImageLogger\n",
      "    params:\n",
      "      batch_frequency: 500\n",
      "      max_images: 8\n",
      "      increase_log_steps: false\n",
      "trainer:\n",
      "  benchmark: true\n",
      "  max_steps: 2000\n",
      "  gpus: 0,\n",
      "\n",
      "Sanity Checking: 0it [00:00, ?it/s]/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Training: 0it [00:00, ?it/s]/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2102: LightningDeprecationWarning: `Trainer.root_gpu` is deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.strategy.root_device.index` instead.\n",
      "  rank_zero_deprecation(\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2102: LightningDeprecationWarning: `Trainer.root_gpu` is deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.strategy.root_device.index` instead.\n",
      "  rank_zero_deprecation(\n",
      "Epoch 0:   0%|                                         | 0/2222 [00:00<?, ?it/s]/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:229: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "Epoch 0:  22%|▏| 499/2222 [11:51<40:56,  1.43s/it, loss=0.337, v_num=0, train/loData shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:00<00:06,  7.96it/s]\u001b[A\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:00<00:06,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:00<00:05,  7.93it/s]\u001b[A\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:00<00:05,  7.92it/s]\u001b[A\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:00<00:05,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:00<00:05,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:00<00:05,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:01<00:05,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:01<00:05,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:01<00:05,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:01<00:04,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:01<00:04,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:01<00:04,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:01<00:04,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:01<00:04,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:02<00:04,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:02<00:04,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:02<00:04,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:02<00:03,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:02<00:03,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:02<00:03,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:02<00:03,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:02<00:03,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:03<00:03,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:03<00:03,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:03<00:03,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:03<00:02,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:03<00:02,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:03<00:02,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:03<00:02,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:03<00:02,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:04<00:02,  7.89it/s]\u001b[A\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:04<00:02,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:04<00:02,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:04<00:01,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:04<00:01,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:04<00:01,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:04<00:01,  7.86it/s]\u001b[A\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:04<00:01,  7.84it/s]\u001b[A\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:05<00:01,  7.83it/s]\u001b[A\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:05<00:01,  7.84it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:05<00:01,  7.85it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:05<00:00,  7.84it/s]\u001b[A\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:05<00:00,  7.86it/s]\u001b[A\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:05<00:00,  7.84it/s]\u001b[A\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:05<00:00,  7.85it/s]\u001b[A\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:05<00:00,  7.84it/s]\u001b[A\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:06<00:00,  7.84it/s]\u001b[A\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:06<00:00,  7.85it/s]\u001b[A\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:06<00:00,  7.89it/s]\u001b[A\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:01<00:58,  1.19s/it]\u001b[A\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:01<00:28,  1.67it/s]\u001b[A\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:01<00:19,  2.44it/s]\u001b[A\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:01<00:14,  3.11it/s]\u001b[A\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:01<00:12,  3.66it/s]\u001b[A\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:02<00:10,  4.11it/s]\u001b[A\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:02<00:09,  4.45it/s]\u001b[A\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:02<00:08,  4.71it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:02<00:08,  4.90it/s]\u001b[A\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:02<00:07,  5.04it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:03<00:07,  5.14it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:03<00:07,  5.21it/s]\u001b[A\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:03<00:07,  5.25it/s]\u001b[A\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:03<00:06,  5.29it/s]\u001b[A\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:03<00:06,  5.31it/s]\u001b[A\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:03<00:06,  5.33it/s]\u001b[A\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:04<00:06,  5.34it/s]\u001b[A\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:04<00:05,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:04<00:05,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:04<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:04<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:05<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:05<00:05,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:05<00:04,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:05<00:04,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:05<00:04,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:06<00:04,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:06<00:04,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:06<00:03,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:06<00:03,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:06<00:03,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:06<00:03,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:07<00:03,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:07<00:02,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:07<00:02,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:07<00:02,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:07<00:02,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:08<00:02,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:08<00:02,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:08<00:01,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:08<00:01,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:08<00:01,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:09<00:01,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:09<00:01,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:09<00:00,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:09<00:00,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:09<00:00,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:09<00:00,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:10<00:00,  5.37it/s]\u001b[A\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:10<00:00,  4.85it/s]\u001b[A\n",
      "Epoch 0:  23%|▏| 500/2222 [12:11<41:58,  1.46s/it, loss=0.331, v_num=0, train/lo/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:378: UserWarning: `ModelCheckpoint(monitor='val/loss_simple_ema')` could not find the monitored key in the returned metrics: ['train/loss_simple', 'train/loss_simple_step', 'train/loss_vlb', 'train/loss_vlb_step', 'train/loss', 'train/loss_step', 'global_step', 'epoch', 'step']. HINT: Did you call `log('val/loss_simple_ema', value)` in the `LightningModule`?\n",
      "  warning_cache.warn(m)\n",
      "Epoch 0, global step 500: 'val/loss_simple_ema' was not in top 1\n",
      "Prunin' Checkpoint\n",
      "Checkpoint Keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "Removing optimizer states from checkpoint\n",
      "This is global step 500.\n",
      "Epoch 0:  45%|▍| 999/2222 [24:20<29:48,  1.46s/it, loss=0.254, v_num=0, train/lopop from empty list\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:00<00:06,  7.57it/s]\u001b[A\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:00<00:06,  7.73it/s]\u001b[A\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:00<00:06,  7.77it/s]\u001b[A\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:00<00:05,  7.80it/s]\u001b[A\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:00<00:05,  7.81it/s]\u001b[A\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:00<00:05,  7.81it/s]\u001b[A\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:00<00:05,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:01<00:05,  7.83it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:01<00:05,  7.83it/s]\u001b[A\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:01<00:05,  7.83it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:01<00:04,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:01<00:04,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:01<00:04,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:01<00:04,  7.72it/s]\u001b[A\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:01<00:04,  7.75it/s]\u001b[A\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:02<00:04,  7.78it/s]\u001b[A\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:02<00:04,  7.78it/s]\u001b[A\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:02<00:04,  7.79it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:02<00:03,  7.80it/s]\u001b[A\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:02<00:03,  7.80it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:02<00:03,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:02<00:03,  7.81it/s]\u001b[A\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:02<00:03,  7.81it/s]\u001b[A\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:03<00:03,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:03<00:03,  7.81it/s]\u001b[A\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:03<00:03,  7.83it/s]\u001b[A\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:03<00:02,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:03<00:02,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:03<00:02,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:03<00:02,  7.80it/s]\u001b[A\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:03<00:02,  7.81it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:04<00:02,  7.81it/s]\u001b[A\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:04<00:02,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:04<00:02,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:04<00:01,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:04<00:01,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:04<00:01,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:04<00:01,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:04<00:01,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:05<00:01,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:05<00:01,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:05<00:01,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:05<00:00,  7.81it/s]\u001b[A\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:05<00:00,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:05<00:00,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:05<00:00,  7.83it/s]\u001b[A\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:06<00:00,  7.83it/s]\u001b[A\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:06<00:00,  7.83it/s]\u001b[A\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:06<00:00,  7.83it/s]\u001b[A\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:06<00:00,  7.81it/s]\u001b[A\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:00<00:09,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:00<00:08,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:00<00:08,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:00<00:08,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:00<00:08,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:01<00:08,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:01<00:08,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:01<00:07,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:01<00:07,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:01<00:07,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:02<00:07,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:02<00:07,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:02<00:06,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:02<00:06,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:02<00:06,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:02<00:06,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:03<00:06,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:03<00:05,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:03<00:05,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:03<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:03<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:04<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:04<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:05<00:04,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:05<00:04,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:05<00:03,  5.34it/s]\u001b[A\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:05<00:03,  5.34it/s]\u001b[A\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:05<00:03,  5.33it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:05<00:03,  5.34it/s]\u001b[A\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:06<00:03,  5.34it/s]\u001b[A\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:06<00:02,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:06<00:02,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:06<00:02,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:06<00:02,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:07<00:02,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:07<00:02,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:07<00:01,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:07<00:01,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:07<00:01,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:08<00:01,  5.33it/s]\u001b[A\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:08<00:01,  5.34it/s]\u001b[A\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:08<00:00,  5.34it/s]\u001b[A\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:08<00:00,  5.34it/s]\u001b[A\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:08<00:00,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:08<00:00,  5.34it/s]\u001b[A\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:09<00:00,  5.34it/s]\u001b[A\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:09<00:00,  5.35it/s]\u001b[A\n",
      "Epoch 0:  45%|▍| 1000/2222 [24:39<30:07,  1.48s/it, loss=0.223, v_num=0, train/lEpoch 0, global step 1000: 'val/loss_simple_ema' was not in top 1\n",
      "Prunin' Checkpoint\n",
      "Checkpoint Keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "Removing optimizer states from checkpoint\n",
      "This is global step 1000.\n",
      "Epoch 0:  67%|▋| 1499/2222 [36:55<17:48,  1.48s/it, loss=0.299, v_num=0, train/lpop from empty list\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:00<00:06,  7.66it/s]\u001b[A\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:00<00:06,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:00<00:05,  7.86it/s]\u001b[A\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:00<00:05,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:00<00:05,  7.92it/s]\u001b[A\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:00<00:05,  7.92it/s]\u001b[A\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:00<00:05,  7.93it/s]\u001b[A\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:01<00:05,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:01<00:05,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:01<00:05,  7.93it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:01<00:04,  7.93it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:01<00:04,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:01<00:04,  7.93it/s]\u001b[A\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:01<00:04,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:01<00:04,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:02<00:04,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:02<00:04,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:02<00:04,  7.95it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:02<00:03,  7.95it/s]\u001b[A\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:02<00:03,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:02<00:03,  7.95it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:02<00:03,  7.96it/s]\u001b[A\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:02<00:03,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:03<00:03,  7.90it/s]\u001b[A\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:03<00:03,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:03<00:03,  7.91it/s]\u001b[A\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:03<00:02,  7.93it/s]\u001b[A\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:03<00:02,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:03<00:02,  7.93it/s]\u001b[A\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:03<00:02,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:03<00:02,  7.95it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:04<00:02,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:04<00:02,  7.93it/s]\u001b[A\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:04<00:02,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:04<00:01,  7.95it/s]\u001b[A\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:04<00:01,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:04<00:01,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:04<00:01,  7.95it/s]\u001b[A\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:04<00:01,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:05<00:01,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:05<00:01,  7.95it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:05<00:01,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:05<00:00,  7.93it/s]\u001b[A\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:05<00:00,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:05<00:00,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:05<00:00,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:05<00:00,  7.94it/s]\u001b[A\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:06<00:00,  7.95it/s]\u001b[A\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:06<00:00,  7.95it/s]\u001b[A\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:06<00:00,  7.93it/s]\u001b[A\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:00<00:09,  5.42it/s]\u001b[A\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:00<00:08,  5.41it/s]\u001b[A\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:00<00:08,  5.40it/s]\u001b[A\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:00<00:08,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:00<00:08,  5.40it/s]\u001b[A\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:01<00:08,  5.40it/s]\u001b[A\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:01<00:07,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:01<00:07,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:01<00:07,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:01<00:07,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:02<00:07,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:02<00:07,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:02<00:06,  5.40it/s]\u001b[A\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:02<00:06,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:02<00:06,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:02<00:06,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:03<00:06,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:03<00:05,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:03<00:05,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:03<00:05,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:03<00:05,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:04<00:05,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:04<00:05,  5.40it/s]\u001b[A\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:04<00:04,  5.40it/s]\u001b[A\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:04<00:04,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:04<00:04,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:05<00:04,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:05<00:04,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:05<00:03,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:05<00:03,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:05<00:03,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:05<00:03,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:06<00:03,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:06<00:02,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:07<00:02,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:07<00:02,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:07<00:01,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:07<00:01,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:07<00:01,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:07<00:01,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:08<00:01,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:08<00:00,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:08<00:00,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:08<00:00,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:08<00:00,  5.39it/s]\u001b[A\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:09<00:00,  5.38it/s]\u001b[A\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:09<00:00,  5.39it/s]\u001b[A\n",
      "Epoch 0:  68%|▋| 1500/2222 [37:13<17:55,  1.49s/it, loss=0.294, v_num=0, train/lEpoch 0, global step 1500: 'val/loss_simple_ema' was not in top 1\n",
      "Prunin' Checkpoint\n",
      "Checkpoint Keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "Removing optimizer states from checkpoint\n",
      "This is global step 1500.\n",
      "Epoch 0:  90%|▉| 1999/2222 [49:30<05:31,  1.49s/it, loss=0.298, v_num=0, train/lpop from empty list\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:00<00:06,  7.60it/s]\u001b[A\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:00<00:06,  7.77it/s]\u001b[A\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:00<00:06,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:00<00:05,  7.82it/s]\u001b[A\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:00<00:05,  7.85it/s]\u001b[A\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:00<00:05,  7.85it/s]\u001b[A\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:00<00:05,  7.84it/s]\u001b[A\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:01<00:05,  7.85it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:01<00:05,  7.85it/s]\u001b[A\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:01<00:05,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:01<00:04,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:01<00:04,  7.85it/s]\u001b[A\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:01<00:04,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:01<00:04,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:01<00:04,  7.86it/s]\u001b[A\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:02<00:04,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:02<00:04,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:02<00:04,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:02<00:03,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:02<00:03,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:02<00:03,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:02<00:03,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:02<00:03,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:03<00:03,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:03<00:03,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:03<00:03,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:03<00:02,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:03<00:02,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:03<00:02,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:03<00:02,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:03<00:02,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:04<00:02,  7.86it/s]\u001b[A\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:04<00:02,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:04<00:02,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:04<00:01,  7.86it/s]\u001b[A\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:04<00:01,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:04<00:01,  7.86it/s]\u001b[A\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:04<00:01,  7.86it/s]\u001b[A\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:04<00:01,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:05<00:01,  7.87it/s]\u001b[A\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:05<00:01,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:05<00:01,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:05<00:00,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:05<00:00,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:05<00:00,  7.89it/s]\u001b[A\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:05<00:00,  7.89it/s]\u001b[A\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:05<00:00,  7.89it/s]\u001b[A\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:06<00:00,  7.88it/s]\u001b[A\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:06<00:00,  7.87it/s]\u001b[A\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:06<00:00,  7.87it/s]\u001b[A\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:00<00:09,  5.35it/s]\u001b[A\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:00<00:08,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:00<00:08,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:00<00:08,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:00<00:08,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:01<00:08,  5.38it/s]\u001b[A\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:01<00:08,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:01<00:07,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:01<00:07,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:01<00:07,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:02<00:07,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:02<00:07,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:02<00:06,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:02<00:06,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:02<00:06,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:02<00:06,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:03<00:06,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:03<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:03<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:03<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:03<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:04<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:04<00:05,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:04<00:04,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:05<00:04,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:05<00:04,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:05<00:03,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:05<00:03,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:05<00:03,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:05<00:03,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:06<00:03,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:06<00:02,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:06<00:02,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:06<00:02,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:06<00:02,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:07<00:02,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:07<00:02,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:07<00:01,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:07<00:01,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:07<00:01,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:08<00:01,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:08<00:01,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:08<00:00,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:08<00:00,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:08<00:00,  5.36it/s]\u001b[A\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:08<00:00,  5.37it/s]\u001b[A\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:09<00:00,  5.37it/s]\u001b[A\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:09<00:00,  5.36it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 2000/2222 [49:49<05:31,  1.49s/it, loss=0.299, v_num=0, train/lEpoch 0, global step 2000: 'val/loss_simple_ema' was not in top 1\n",
      "Prunin' Checkpoint\n",
      "Checkpoint Keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "Removing optimizer states from checkpoint\n",
      "This is global step 2000.\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2102: LightningDeprecationWarning: `Trainer.root_gpu` is deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.strategy.root_device.index` instead.\n",
      "  rank_zero_deprecation(\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2102: LightningDeprecationWarning: `Trainer.root_gpu` is deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.strategy.root_device.index` instead.\n",
      "  rank_zero_deprecation(\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2028: LightningDeprecationWarning: `Trainer.training_type_plugin` is deprecated in v1.6 and will be removed in v1.8. Use `Trainer.strategy` instead.\n",
      "  rank_zero_deprecation(\n",
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2028: LightningDeprecationWarning: `Trainer.training_type_plugin` is deprecated in v1.6 and will be removed in v1.8. Use `Trainer.strategy` instead.\n",
      "  rank_zero_deprecation(\n",
      "Average Epoch time: 3003.85 seconds\n",
      "Average Peak memory 20238.11MiB\n",
      "Epoch 0:  90%|▉| 2000/2222 [50:03<05:33,  1.50s/it, loss=0.299, v_num=0, train/l\n",
      "Training complete. max_training_steps reached or we blew up.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# This isn't used for training, just to help you remember what your trained into the model.\n",
    "project_name = \"project_name\"\n",
    "\n",
    "# MAX STEPS\n",
    "# How many steps do you want to train for?\n",
    "max_training_steps = 2000\n",
    "\n",
    "# Match class_word to the category of the regularization images you chose above.\n",
    "class_word = \"person\" # typical uses are \"man\", \"person\", \"woman\"\n",
    "\n",
    "# This is the unique token you are incorporating into the stable diffusion model.\n",
    "token = \"joyce\"\n",
    "\n",
    "\n",
    "reg_data_root = \"/home/chengping/Dreambooth-Stable-Diffusion/regularization_images/\" + dataset\n",
    "\n",
    "!rm -rf training_images2/.ipynb_checkpoints\n",
    "!rm -rf regularization_images/person_ddim/.ipynb_checkpoints\n",
    "!CUDA_VISIBLE_DEVICES=1 python \"main.py\" \\\n",
    " --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
    " -t \\\n",
    " --actual_resume \"/data/chengping/ldm-ckpt/ori/sd-v1-4-full-ema.ckpt\" \\\n",
    " --reg_data_root \"{reg_data_root}\" \\\n",
    " -n \"{project_name}\" \\\n",
    " --gpus 0, \\\n",
    " --data_root \"/home/chengping/Dreambooth-Stable-Diffusion/training_images2\" \\\n",
    " --max_training_steps {max_training_steps} \\\n",
    " --class_word \"{class_word}\" \\\n",
    " --token \"{token}\" \\\n",
    " --no-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49d0bd",
   "metadata": {},
   "source": [
    "## Copy and name the checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6fcb0cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download your trained model file from trained_models/2022-10-07T05-53-45_project_name_20_training_images_2000_max_training_steps_joyce_token_person_class_word.ckpt and use in your favorite Stable Diffusion repo!\n"
     ]
    }
   ],
   "source": [
    "# Copy the checkpoint into our `trained_models` folder\n",
    "\n",
    "directory_paths = !ls -d logs/*\n",
    "last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
    "training_images = !find training_images/*\n",
    "date_string = !date +\"%Y-%m-%dT%H-%M-%S\"\n",
    "file_name = date_string[-1] + \"_\" + project_name + \"_\" + str(len(training_images)) + \"_training_images_\" +  str(max_training_steps) + \"_max_training_steps_\" + token + \"_token_\" + class_word + \"_class_word.ckpt\"\n",
    "!mkdir -p trained_models\n",
    "!mv {last_checkpoint_file} trained_models/{file_name}\n",
    "\n",
    "print(\"Download your trained model file from trained_models/\" + file_name + \" and use in your favorite Stable Diffusion repo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c5125e",
   "metadata": {},
   "source": [
    "# Optional - Upload to google drive\n",
    "* run the following commands in a new `terminal` in the `Dreambooth-Stable-Diffusion` directory\n",
    "* `chmod +x ./gdrive`\n",
    "* `./gdrive about`\n",
    "* `paste your token here after navigating to the link`\n",
    "* `./gdrive upload trained_models/{file_name.ckpt}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90ac5c",
   "metadata": {},
   "source": [
    "# Big Important Note!\n",
    "\n",
    "The way to use your token is `<token> <class>` ie `joepenna person` and not just `joepenna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe64d303-873c-4e28-8db3-a380a9dfe66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-10-06T06-56-28_project_name_20_training_images_2000_max_training_steps_chengping_token_person_class_word.ckpt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d0139",
   "metadata": {},
   "source": [
    "## Generate Images With Your Trained Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80ddb03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "Global seed set to 42\n",
      "Loading model from /home/chengping/Dreambooth-Stable-Diffusion/trained_models/2000.ckpt\n",
      "Global Step: 2000\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'text_projection.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'logit_scale', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'visual_projection.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Sampling:   0%|                                           | 0/4 [00:00<?, ?it/s]\n",
      "data:   0%|                                               | 0/1 [00:00<?, ?it/s]\u001b[AData shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:01<01:07,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:01<00:30,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:01<00:18,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:01<00:13,  3.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:01<00:09,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:01<00:08,  5.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:02<00:06,  6.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:02<00:06,  6.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:02<00:05,  7.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:02<00:05,  7.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:02<00:04,  8.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:02<00:04,  8.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:02<00:04,  8.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:02<00:04,  8.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:02<00:03,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:03<00:03,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:03<00:03,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:03<00:03,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:03<00:03,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:03<00:03,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:03<00:03,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:03<00:03,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:03<00:03,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:03<00:02,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:04<00:02,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:04<00:02,  8.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:04<00:02,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:04<00:02,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:04<00:02,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:04<00:02,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:04<00:02,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:04<00:02,  8.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:04<00:01,  8.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:05<00:01,  8.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:05<00:01,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:05<00:01,  8.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:05<00:01,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:05<00:01,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:05<00:01,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:05<00:01,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:05<00:01,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:05<00:00,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:06<00:00,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:06<00:00,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:06<00:00,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:06<00:00,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:06<00:00,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:06<00:00,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:06<00:00,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:06<00:00,  7.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "data: 100%|███████████████████████████████████████| 1/1 [00:07<00:00,  7.72s/it]\u001b[A\n",
      "Sampling:  25%|████████▊                          | 1/4 [00:07<00:23,  7.72s/it]\n",
      "data:   0%|                                               | 0/1 [00:00<?, ?it/s]\u001b[AData shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:00<00:05,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:00<00:05,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:00<00:05,  8.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:00<00:05,  8.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:00<00:05,  8.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:00<00:05,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:00<00:04,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:00<00:04,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:01<00:04,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:01<00:04,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:01<00:04,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:01<00:04,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:01<00:04,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:01<00:04,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:01<00:03,  8.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:01<00:03,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:01<00:03,  8.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:02<00:03,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:02<00:03,  8.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:02<00:03,  8.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:02<00:03,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:02<00:03,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:02<00:03,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:02<00:02,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:02<00:02,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:02<00:02,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:03<00:02,  8.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:03<00:02,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:03<00:02,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:03<00:02,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:03<00:02,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:03<00:02,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:03<00:01,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:03<00:01,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:03<00:01,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:04<00:01,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:04<00:01,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:04<00:01,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:04<00:01,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:04<00:01,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:04<00:01,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:04<00:00,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:04<00:00,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:04<00:00,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:05<00:00,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:05<00:00,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:05<00:00,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:05<00:00,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:05<00:00,  8.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:05<00:00,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "data: 100%|███████████████████████████████████████| 1/1 [00:05<00:00,  5.77s/it]\u001b[A\n",
      "Sampling:  50%|█████████████████▌                 | 2/4 [00:13<00:13,  6.57s/it]\n",
      "data:   0%|                                               | 0/1 [00:00<?, ?it/s]\u001b[AData shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:00<00:05,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:00<00:05,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:00<00:05,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:00<00:05,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:00<00:05,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:00<00:04,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:00<00:04,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:00<00:04,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:01<00:04,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:01<00:04,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:01<00:04,  8.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:01<00:04,  8.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:01<00:04,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:01<00:04,  8.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:01<00:03,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:01<00:03,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:01<00:03,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:02<00:03,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:02<00:03,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:02<00:03,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:02<00:03,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:02<00:03,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:02<00:03,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:02<00:02,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:02<00:02,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:02<00:02,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:03<00:02,  8.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:03<00:02,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:03<00:02,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:03<00:02,  8.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:03<00:02,  9.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:03<00:02,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:03<00:01,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:03<00:01,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:03<00:01,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:04<00:01,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:04<00:01,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:04<00:01,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:04<00:01,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:04<00:01,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:04<00:01,  8.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:04<00:00,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:04<00:00,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:04<00:00,  8.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:05<00:00,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:05<00:00,  8.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:05<00:00,  8.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:05<00:00,  8.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:05<00:00,  8.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:05<00:00,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "data: 100%|███████████████████████████████████████| 1/1 [00:05<00:00,  5.77s/it]\u001b[A\n",
      "Sampling:  75%|██████████████████████████▎        | 3/4 [00:19<00:06,  6.21s/it]\n",
      "data:   0%|                                               | 0/1 [00:00<?, ?it/s]\u001b[AData shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n",
      "\n",
      "\n",
      "DDIM Sampler:   0%|                                      | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   2%|▌                             | 1/50 [00:00<00:05,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   4%|█▏                            | 2/50 [00:00<00:05,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   6%|█▊                            | 3/50 [00:00<00:05,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:   8%|██▍                           | 4/50 [00:00<00:05,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  10%|███                           | 5/50 [00:00<00:05,  8.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  12%|███▌                          | 6/50 [00:00<00:04,  8.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  14%|████▏                         | 7/50 [00:00<00:04,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  16%|████▊                         | 8/50 [00:00<00:04,  8.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  18%|█████▍                        | 9/50 [00:01<00:04,  8.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  20%|█████▊                       | 10/50 [00:01<00:04,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  22%|██████▍                      | 11/50 [00:01<00:04,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  24%|██████▉                      | 12/50 [00:01<00:04,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  26%|███████▌                     | 13/50 [00:01<00:04,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  28%|████████                     | 14/50 [00:01<00:04,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  30%|████████▋                    | 15/50 [00:01<00:03,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  32%|█████████▎                   | 16/50 [00:01<00:03,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  34%|█████████▊                   | 17/50 [00:01<00:03,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  36%|██████████▍                  | 18/50 [00:02<00:03,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  38%|███████████                  | 19/50 [00:02<00:03,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  40%|███████████▌                 | 20/50 [00:02<00:03,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  42%|████████████▏                | 21/50 [00:02<00:03,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  44%|████████████▊                | 22/50 [00:02<00:03,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  46%|█████████████▎               | 23/50 [00:02<00:03,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  48%|█████████████▉               | 24/50 [00:02<00:02,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  50%|██████████████▌              | 25/50 [00:02<00:02,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  52%|███████████████              | 26/50 [00:02<00:02,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  54%|███████████████▋             | 27/50 [00:03<00:02,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  56%|████████████████▏            | 28/50 [00:03<00:02,  8.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  58%|████████████████▊            | 29/50 [00:03<00:02,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  60%|█████████████████▍           | 30/50 [00:03<00:02,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  62%|█████████████████▉           | 31/50 [00:03<00:02,  8.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  64%|██████████████████▌          | 32/50 [00:03<00:02,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  66%|███████████████████▏         | 33/50 [00:03<00:01,  8.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  68%|███████████████████▋         | 34/50 [00:03<00:01,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  70%|████████████████████▎        | 35/50 [00:03<00:01,  8.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  72%|████████████████████▉        | 36/50 [00:04<00:01,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  74%|█████████████████████▍       | 37/50 [00:04<00:01,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  76%|██████████████████████       | 38/50 [00:04<00:01,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  78%|██████████████████████▌      | 39/50 [00:04<00:01,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  80%|███████████████████████▏     | 40/50 [00:04<00:01,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  82%|███████████████████████▊     | 41/50 [00:04<00:01,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  84%|████████████████████████▎    | 42/50 [00:04<00:00,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  86%|████████████████████████▉    | 43/50 [00:04<00:00,  8.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  88%|█████████████████████████▌   | 44/50 [00:04<00:00,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  90%|██████████████████████████   | 45/50 [00:05<00:00,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  92%|██████████████████████████▋  | 46/50 [00:05<00:00,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  94%|███████████████████████████▎ | 47/50 [00:05<00:00,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  96%|███████████████████████████▊ | 48/50 [00:05<00:00,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler:  98%|████████████████████████████▍| 49/50 [00:05<00:00,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "DDIM Sampler: 100%|█████████████████████████████| 50/50 [00:05<00:00,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "data: 100%|███████████████████████████████████████| 1/1 [00:05<00:00,  5.80s/it]\u001b[A\n",
      "Sampling: 100%|███████████████████████████████████| 4/4 [00:25<00:00,  6.27s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"scripts/stable_txt2img.py\", line 292, in <module>\n",
      "    main()\n",
      "  File \"scripts/stable_txt2img.py\", line 275, in main\n",
      "    save_image(grid[i, :, :, :], os.path.join(outpath,opt.prompt+'_{}.png'.format(i)))\n",
      "  File \"/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/torchvision/utils.py\", line 136, in save_image\n",
      "    im.save(fp, format=format)\n",
      "  File \"/data/chengping/miniconda3/envs/ldm/lib/python3.8/site-packages/PIL/Image.py\", line 2209, in save\n",
      "    fp = builtins.open(filename, \"w+b\")\n",
      "OSError: [Errno 36] File name too long: 'outputs/txt2img-samples/Portrait of chengping person with steampunk weapons and uniform, serious, side view zoomed out anime digital painting, beautiful eyes!, pretty face!!, symmetry, concept art, sharp focus, illustration, art by artgerm! greg rutkowski magali villeneuve wlop! ilya kuvshinov!!, octane render _0.png'\n"
     ]
    }
   ],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 1 \\\n",
    " --n_iter 4 \\\n",
    " --scale 7.0 \\\n",
    " --ddim_steps 50 \\\n",
    " --ckpt \"/home/chengping/Dreambooth-Stable-Diffusion/trained_models/2000.ckpt\" \\\n",
    " --prompt \"Portrait of chengping person with steampunk weapons and uniform, serious, side view zoomed out anime digital painting, beautiful eyes!, pretty face!!, symmetry, concept art, sharp focus, illustration, art by artgerm! greg rutkowski magali villeneuve wlop! ilya kuvshinov!!, octane render \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471eee05-584f-4fdb-945c-0230e793be05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "ldm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
